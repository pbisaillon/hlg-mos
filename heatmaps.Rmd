---
title: "Hackathon"
author: "INS"
date: "25/01/2022"
output: html_document
---

```{r setup, include=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo=TRUE)

# Load in libraries and retrieve data -------------------------------------
library(tidyverse)
library(synthpop)
library(reshape2)
library(emdist)

# Source R script from GitHub
satgpa <-
  readr::read_csv("./data/satgpa.csv") %>%
  select(-sat_sum) 
  # removed this from the data set because it's dependent on sat_m and sat_v

synth_bisaillon <-
  readr::read_csv("./synthpop/synth_data.csv")

# Get upper triangle of the correlation matrix
## this will remove the top half of the values for the heat map for a cleaner look
get_upper_tri <- function(cormat) {
  cormat[lower.tri(cormat)] <- NA
  return(cormat)
}
```
## R synthpop

The synthetic data was produced using the function `syn()` and the summaries seen below were produced from using the function `summary()` from the `synthpop` library.

### Original data

```{r sum_og, echo=FALSE}
summary(satgpa)
```

### Synthetic data

```{r sum_syn, echo=FALSE}
summary(synth_bisaillon)
```

## Heat maps (correlation matrices)

These plots show the correlation between two variables. This type of data validation is useful if the data is Gaussian (i.e., it is normally distributed). If the data were skewed, this would not be a sufficient test as this only looks at the correlation between two variables at a time. This is an appropriate test if the intended use is to be able to perform calculations based on mean and/or covariance in one-dimension. Otherwise, if the intended use of the synthetic data is to look at relationships between multiple variables (e.g., sex, sat_v, and fy_gpa) then this test would not return that information appropriately [how do I word this better???]. 

Should I completely rely on this test? Probably not. It depends on your use-case. 

These heat maps can be used to preliminary verify how similar the synthetic data is to the original data, assuming that the data are normally distributed, by comparing the correlations of two variables in the respective data sets. The heat map makes it easy to visually compare if the two data sets are producing similar results.

To examine relationships between multiple variables at a time, we can look at the Earth Mover's Distance (Wasserstein) which will be discussed in the next section.

:::::::::::::: {.columns}
::: {.column width="50%"}

### Original data
```{r plot1, echo=FALSE, warning=FALSE}
# Compute the variance of x and the covariance or correlation of x and y if these are vectors
cormat <- round(cor(satgpa), 2)
upper_tri <- get_upper_tri(cormat)
# Convert an object into a molten data frame
melted_cormat <- melt(upper_tri, na.rm = TRUE)

# Create a ggheatmap
heat <-
  ggplot(data = melted_cormat, aes(Var2, Var1, fill = value)) +
  geom_tile(color = "white") +
  scale_fill_gradient2(
    low = "blue",
    high = "red",
    mid = "white",
    midpoint = 0,
    limit = c(-1, 1),
    space = "Lab",
    name = "Pearson Correlation"
  ) +
  theme_minimal() +
  geom_text(aes(Var2, Var1, label = value), color = "black", size = 4) +
  theme(
    axis.text.x = element_text(
      vjust = 1,
      size = 12,
      hjust = 1
    ),
    axis.text.y = element_text(
      vjust = 1,
      size = 12,
      hjust = 1
    ),
    axis.title.x = element_blank(),
    axis.title.y = element_blank(),
    panel.grid.major = element_blank(),
    panel.border = element_blank(),
    panel.background = element_blank(),
    axis.ticks = element_blank(),
    legend.justification = c(1, 0),
    legend.position = c(0.55, 0.65),
    legend.direction = "horizontal") +
  guides(fill = guide_colorbar(
    barwidth = 7,
    barheight = 1,
    title.position = "top",
    title.hjust = 0.5
  )) +
  coord_fixed()

print(heat)
```

:::
::: {.column width="50%"}

### Synthetic data
```{r plot2, echo=FALSE, warning=FALSE}
# Compute the variance of x and the covariance or correlation of x and y if these are vectors
cormat <- round(cor(synth_bisaillon), 2)
upper_tri <- get_upper_tri(cormat)
# Convert an object into a molten data frame
melted_cormat <- melt(upper_tri, na.rm = TRUE)

# Create a ggheatmap
heat <-
  ggplot(data = melted_cormat, aes(Var2, Var1, fill = value)) +
  geom_tile(color = "white") +
  scale_fill_gradient2(
    low = "blue",
    high = "red",
    mid = "white",
    midpoint = 0,
    limit = c(-1, 1),
    space = "Lab",
    name = "Pearson Correlation"
  ) +
  theme_minimal() +
  geom_text(aes(Var2, Var1, label = value), color = "black", size = 4) +
  theme(
    axis.text.x = element_text(
      vjust = 1,
      size = 12,
      hjust = 1
    ),
    axis.text.y = element_text(
      vjust = 1,
      size = 12,
      hjust = 1
    ),
    axis.title.x = element_blank(),
    axis.title.y = element_blank(),
    panel.grid.major = element_blank(),
    panel.border = element_blank(),
    panel.background = element_blank(),
    axis.ticks = element_blank(),
    legend.justification = c(1, 0),
    legend.position = c(0.55, 0.65),
    legend.direction = "horizontal") +
  guides(fill = guide_colorbar(
    barwidth = 7,
    barheight = 1,
    title.position = "top",
    title.hjust = 0.5
  )) +
  coord_fixed()

print(heat)
```
> Note: synthpop` generates randomized numbers for the synthetic data; therefore, multiple outputs may not produce the same numbers. However, the synthetic data outputs should still be fairly similar [do we know how similar they should be?] that we only really need to show one comparison to demonstrate that the synthetic data shows similar correlations to the original data.

:::
::::::::::::::

## Earth Mover's Distance

More infomation re: Earth Mover's Distance can be found [here](https://www.rdocumentation.org/packages/emdist/versions/0.3-1/topics/emd).

------

### Excerpts from the [emdist documentation](https://www.rdocumentation.org/packages/emdist/versions/0.3-1/topics/emd) 

#### Value

Earth Mover's Distance (EMD) between of the distributions `A` and `B`. If `A` and `B` are not distributions then `A` is the source and `B` is the target.

#### Details

`emd2d` interprets the two matrices `A` and `B` as a distribution over a two-dimensional grid. The distance between the grid points in each direction is defined by `xdist` and `ydist.` Both matrices must have the same dimensionality.
`emd` uses first column of each matrix as the weighs and the remaining columns as location coordinates in a up to four-dimensional space. `A` and `B` **must have the same number of columns**. `emdw` separates the weights from the location matrices but is otherwise identical to `emd`. `emdr` uses the original EMD implementation by Yossi Rubner from Stanford. In case A and B are not densities, the weighted sum of flows is normalized by the smaller total mass of the two. The version of the `emd` package released on CRAN contains only this implementation and all other functions are just front-ends for the call to `emdr.`

#### Note re: the distance argument

[D]istance (dist) to be used for the computation of the cost over the locations. Must be either `"euclidean"`, `"manhattan"` or a [metric over a] closure taking two vectors and returning a scalar number. The latter case is much less efficient because it requires R evaluation for every possible combination of flows.

------

The main thing to note about the difference between `emd` and `emd2d` is that `emd` looks at vectors whereas `emd2d` looks at points; therefore, the latter calculates more combinations than the former. This would also explain why the `emd2d` result shows a value that is "more distant" than the `emd` result. Essentially, because `emd2d` looks at more combinations it has more to iterate over. 

```{r emd, echo=FALSE, warning=FALSE}
# mat_satgpa <- satgpa %>% as.matrix()
# mat_synth <- synth_bisaillon %>% as.matrix()

# emd(mat_satgpa, mat_synth, dist = "euclidean")
# [1] 1.243486
# Time difference of 5.467048 secs

# emd2d(mat_satgpa, mat_synth, dist = "euclidean")
# [1] 2.925377
# Time difference of 30.70497 mins (for euclidean)
# Time difference of 33.62831 mins (for manhattan)
```

Below are the results and run-time for each EMD function:

Function | Result | Run-time
|---|---|---|
`emd` | 1.243486 | 5.467048 secs
`emd2d` | 2.925377 | 30.70497 mins

The result that is returned shows us how close our synthetic data is to the original data. Ideally, you would want a value of 0 (or close to 0). However, since we do not have a pre-determined threshold to gauge proximity it cannot be determined whether values returned are "close enough" to the original data set.

This threshold may differ for users depending on their use case. Nonetheless, this test can show how similar the data are to one another.

Which function should you use? It depends on your use-case.

If the goal is to create synthetic data that is as close as possible to the original data then it might be useful to use `emd2d` to get the most accurate picture (of the two functions). Keep in mind that this function takes significantly longer to run than `emd`. Regardless of which option you choose to run as your final test, it would be prudent to run `emd` first and see that result prior to running `emd2d`. The reason would be that `emd` is time-effective and if you return a high value with this function, you would probably return an even higher value with `emd2d`. In that, if you returned a value above your desired threshold, it might be more valuable to modify the parameters of your synthetic data before testing it further.